%=========================================================================
% (c) Michal Bidlo, Bohuslav Křena, 2008

\definecolor{gray}{gray}{0.5}
\newcommand{\todo}[1]{\textcolor{red}{TODO\:} \textcolor{gray}{#1}}

\chapter{Introduction}\label{introduction}

Subject of this thesis project is constructing a C programming language compiler for the soft-core processor PicoBlaze-6.

    \section{The C Programming Language}

    \todo{citace, citace, citace}

    The C programming language was created in the seventies \todo{spisovne?}
    of the twentieth century by Dennis Ritchie and Ken Thompson. In this project, I focused mainly on implementing its two latest standards, ISO/IEC 9899:1999 and partially ISO/IEC 9899:2011.

    \section{The Previous Project}
    Similar thesis topic was elaborated by Jakub Horník as his \todo{citace}
    master's thesis in year 2011.

    While he was writing the thesis, a new version of the target processor was released (see chapter~\ref{processor}). More of the resulting application is discussed in section~\ref{prev_pbcc}.

\chapter{The PicoBlaze Processor}\label{processor}

Picoblaze is a 8-bit processor created by Xilinx Inc. for their Spartan and Virtex FPGA\footnote{Field-programmable gate array} series as an embeddable circuit to implement sequential programming in the parallel FPGA architecture. This of course means the processor is not meant to be physically manufactured, yet it would be possible.

Historically, the name of the design was \texttt{KCPSM}, for \emph{Ken Chapman's Programmable State Machine} and then \emph{Constant Coded Programmable State Machine}. This term is now still used in the FPGA design - the components are still caled \texttt{kcpsmX} where \texttt{X} stands for the version of the processor.

The fact the processor is soft-core only makes shipping bug fix and feature updates possible to the users of the current version. The most up to date release of the current version is the 8th one, published on March 31, 2014.\todo{release7: http://forums.xilinx.com/t5/PicoBlaze/Release-7-of-KCPSM6-What-s-New/m-p/385325 na webu ale visi uz 8}.

The previous version, PicoBlaze-3, had its last 7th revision released in October 2003. \todo{citace nebo aspon link na forum}

    \section{Main Features}

    \emph{PicoBlaze} is a RISC\footnote{Reduced Instruction Set Computing}, Harvard architecture\footnote{The program code and the data memory are stored in separate locations} processor. Every instruction is executed in 2 clock cycles.

    \begin{center}
    \begin{tabular}{ @{\extracolsep{\fill} } r | l }
        Program memory & Up to 4096 instructions \\

        Scratchpad RAM & Up to 256 bytes \\

        2 Register banks & Containing 16 8-bit registers each\\

        Output & 256 8-bit ports \\

        8-bit ALU & Supports shifting, adding and subtracting \\
                  & Provides AND, OR and XOR operations \\
                  & Compares and tests \\
                  & Implements carry and zero flags \\

        FPGA design & Can be included directly in the VHDL code \\
                    & No other equipment or code needed \\
    \end{tabular}
    \end{center}

    \section{Practical usage}

    A sequential processor, in comparison to parallel hardware design, is much more feasible for implementing state machines and computational cycles.

    \todo{Pripadne nejake linky na pripady/priklady uziti atp}

    \section{New features and properties of PicoBlaze-6}

    Compared to the previous version, there were major changes in PicoBlaze's design after the upgrade to the sixth version, which is still backwards-compatible.

    The most important ones are covered in this section in descending order according to their impact on programming in C and the compiler itself.

        \subsection{New \texttt{JUMP@} and \texttt{CALL@} Instructions}\label{jumpat}

        Indirect jumps and calls, provided the address of the function or label, are possible in the new version.

        This improves compatibility with sophisticated C programs greatly as it allows the implementation of function pointers and their calling.

        It also means there had to a new addressing mode introduced - the whole program memory cannot be covered with only an 8-bit value, so the code's section is stored in the lower four bytes of the first register and the rest of the address in the second one.

        \subsection{New \texttt{REGBANK} and \texttt{STAR} Instructions}

        The new version of the processor now provides two sets of 16 general purpose registers that are switchable using the \texttt{REGBANK} instruction - this means only one of the sets can be accessed at a time.

        To store values in the inactive bank, the \texttt{STAR} instruction is provided - it is used to store a value from the active bank register in another register that is in the inactive bank.

        \subsection{\texttt{ADDCY} and \texttt{SUBCY} Instruction Changes}

        The previous version of these instructions modified the zero flag only according to their own result. Now they add the previous zero to the current one.

        \subsection{New \texttt{COMPARECY} and \texttt{TESTCY} Instructions}

        Instructions added to make comparing multi-byte types easier. They store the flags (carry and zero) and propagate them according to the progress through the single bytes.

        \subsection{Program Memory Changes}

        Due to the two newly added memory addressing pins, it is possible to address four times more program memory (now up to 4K), increasing the possible program size and complexity.

        \subsection{RAM Changes}

        The amount of RAM addressable by the program was increased to up to 256 bytes from 64, yet it depends on the target device the processor will be implemented on. 

        This was achieved by modifying the opcodes of instructions of the processor, not the internals.

        \subsection{Call stack}

        Only 30 levels of function call depth are now available compared to 31 of KCPSM3.

        \subsection{New \texttt{LOAD\&RETURN} Instruction and \texttt{STRING} Directive}

        The user (or compiler) can now specify a byte string location in the memory using the \texttt{STRING} directive in the assembly.

        Then, using the \texttt{LOAD\&RETURN} instruction, it is possible to load a constant value into a specified register and unconditionally return from a subroutine, making these very useful in conjunction to generate text strings to be presented to the user.

        \subsection{New \texttt{OUTPUTK} Instruction}

        This instruction allows the program to output a constant instead of loading it into a register and outputting it using the regular \texttt{OUTPUT}.

    \section{PacoBlaze}

    There is an open-source\footnote{BSD licensed} clone of the \emph{PicoBlaze} processor written in Verilog.

    Its main devise is the possibility to use it with hardware not provided by Xilinx and modifiability and configurability. Due to the higher versatility, \emph{PacoBlaze} is not as efficient (resource-wise) as the original implementation but it enables the user to remove unneeded parts from the processor and use the smallest required subset - reducing field usage possibly.

    The latest version is 2.2 that was released in the year 2007 so it cannot possibly implement the new instructions of PicoBlaze-6 which this project tries to use as much as possible.

\chapter{Programming language compiler}

Most of the modern computer processors are programmed using a fairly complicated binary instruction set. To make writing more complex and powerful applications, we are now using programming languages that are translated (\emph{compiled}) into the low level binary form easily understood by the processor.

In this chapter, the most vital parts and terms in construction of a compiler are discussed, with focus on C language.

    \section{Compiler Structure}

    A typical programming language compiler consists of two to four main parts:

    First part is the optional preprocessor which prepares the source code for the front-end, for example by removing comments or expanding macro definitions.

    A language front-end, which transforms the code from a programming language to its simple intermediate and internal representation.

    An intermediate code optimizer searches the representation for patterns that can be changed to more efficient, smaller or faster equivalents. This part, due to its nature, is optional, too.

    And finally, the back-end, that generates the target code for the processor itself, be it assembly code, virtual machine code or a processor-native code.

    \begin{center}\begin{tikzpicture}
    \tikzstyle{block} = [draw, rectangle, minimum width=14.5em, minimum height=2.2em]
    \node (Program) {\emph{Source Program}};
    \node[block,right=of Program,thick] (Preprocessor) {Preprocessor};
    \node[block,below=of Preprocessor,thick] (Front) {Front-End};
    \node[block,below=of Front,thick] (IMO) {Intermediate Code Optimizer};
    \node[block,below=of IMO,thick] (Back) {Back-End};
    \node[right=of Back,font=\bf,thick] (Target) {\emph{Target Code}};

    \draw[->, thick] (Program) edge (Preprocessor);
    \draw[->,thick] (Preprocessor) edge node[auto] {\emph{Stripped Source Code}} (Front.north);
    \draw[->,thick] (Front) edge node[auto] {\emph{Intermediate Code}} (IMO);
    \draw[->,thick] (IMO) edge node[auto] {\emph{Optimized Intermediate Code}} (Back);
    \draw[->,thick] (Back) edge (Target);

    \end{tikzpicture}\end{center}

        \subsection{Preprocessor}

        Preprocessor performs a simple task of removing or replacing text in the input source code according to some pre-set rules.

        The most common task is removing comments to leave only language defined tokens for the further stages of compilation.

        In the C programming language, there are preprocessor macros, too. These serve a purpose of replacing and inserting text. However, describing the entirety of the C preprocessor is a task beyond limits of this thesis, only few directives are listed, along with their simplified descriptions.

        \begin{center}\begin{tabular}{r|l}
            \verb|#include "file"| or \verb|<file>| & Behaves as if the whole contents of \verb|file| were inserted \\
            & instead of it\\
            \verb|#define MACRO ...| & Every occurence of \verb|NAME| in the code is replaced with \\
            & what is substituted with \verb|...| (until the end of line)\\
            \verb|#if cond| & The following lines until \verb|#endif| are pasted if \verb|cond| is\\
            & met. \verb|cond| supports C expression syntax.\\
            \verb|#ifdef MACRO| & Equivalent to \verb|#if defined(MACRO)|. True if \verb|MACRO| was\\
            & defined.\\
        \end{tabular}\end{center}

        \subsection{Front-end}

            The central and most important part of the compiler, it does a whole set of operations over the source code to produce its independent representation.

            It is a language-specific part, that also checks the correctness of the input code.

            Large compiler projects even aim to its complete and clear replaceability \ref{gcc} \ref{llvm} to benefit from the optimizations in the following stages of compilation.

            \begin{center}\begin{tikzpicture}
            \tikzstyle{block} = [draw, rectangle, minimum width=10em, minimum height=2.2em]
            \node (Program) {\emph{Source Program}};
            \node[block,right=of Program,thick] (Lex) {Lexical Analyzer};
            \node[block,right=of Lex,thick] (Parser) {Parser};
            \node[block,below=of Lex,thick] (SymTab) {Symbol Table};
            \node[block,right=of SymTab,thick] (CodeGen) {Code Generator};
            \node[below=of CodeGen,font=\bf,thick] (IM) {\emph{Intermediate Code}};

            \draw[->,thick] (Program) -- (Lex);
            \draw[transform canvas={yshift=0.5ex},->,thick] (Lex) -- (Parser);
            \draw[transform canvas={yshift=-0.5ex},<-,thick] (Lex) -- (Parser);
            \draw[transform canvas={xshift=0.5ex},->,thick] (CodeGen) -- (Parser);
            \draw[transform canvas={xshift=-0.5ex},<-,thick] (CodeGen) -- (Parser);
            \draw[<->,thick] (Lex) -- (SymTab);
            \draw[<->,thick] (SymTab) -- (CodeGen);
            \draw[->,thick] (CodeGen) -- (IM);

            \end{tikzpicture}\end{center}

            \subsubsection{Lexical analysis}

                As the first part of the front-end, the input string of characters is broken into tokens according to the grammatical rules which are set by the language standard.

                In the case of the C language, they are in the form of regular expressions which means they are being matched by a state machine.
                
            \subsubsection{Symbol Table}

            \subsubsection{Parser}


            \subsubsection{Code Generator}


        \subsection{Intermediate Code}

            \subsubsection{The Intermediate Code Optimizer}

                Being input the intermediate code, it makes it smaller and/or more efficient, regardless of the target architecture.

        \subsection{Back\-end}

            The input in this case is the intermediate language, too. The back-end then takes it and transofrms it to the target assembly or directly the binary form for the target processor architecture.

            Architecture-dependent optimizations can take place in this phase.

\chapter{Compiler Choice}\label{compiler}

As starting a new compiler from scratch would not be possible in the limited time frame of a bachelor's thesis, I had to choose an existing front-end and provide a corresponding back-end part for the target platform.

This basically rules out all of the proprietary compilers and the selection limited to those from the world of free and open source software. In the end, the choice consisted of the following three ones:

    \todo{celkem wall of text (u vsech) bez struktury a refenci}

    \section{GNU Compiler Collection}\label{gcc}

    The GNU Compiler Collection, more known as \texttt{GCC}, was started as a simple C compiler in year 1985 by Richard Stallman. It is now one of the most widely used compiler suites not only in open source systems.

    Due to its huge history and background, its code base is stable and mature but it also is very hard to read due to historical reasons and the fact basically everything is wrapped in several layers of macros.

    The documentation of the inner functionality is not very well arranged and it is hard to find it. Because of its heritage, the structure does not seem very transparent.

    Free Software Foundation and the GNU Project are holding governance over the development and are prohibiting major changes to the architecture or code style which drives many new developers away.

    \section{Low Level Virtual Machine}\label{llvm}

    LLVM is a modern project with a gaining popularity in past years for implementing the features very fast and providing of interesting and useful tools, like static analyzer.

    Its C and C++ front-end, Clang, is adding the latest features of the new language standards and their drafts sooner than the competitors.

    Compared to GCC, LLVM is a really young project. It was founded in 2005. The codebase is dynamically changing, written in C++ with heavy usage of templates and automatically generated code.

    Its development is sponsored by companies like Google, for example to provide ability to run native applications in the browser (NaCl project) or Apple, which utilizes the ecosystem in the official development toolkit provided for their products.

    LLVM provides a very well documented intermediate representation of the compiled source code. Its documentation is publicly visible on their wiki page, every necessary detail is described and the community provides several easy ways to be approached.

        \subsection{Architecture}

        LLVM is strictly separated into front and back ends, divided by the LLVM intermediate code that is heavily optimized and is runnable directly in a virtual machine (hence the name Low Level \emph{Virtual Machine})

    \section{Small Device C Compiler}{sdcc}

    SDCC is a simple (compared to the previous two) compiler aimed to be easily retargetable and provide a quality background for creating compilers for 8bit processors.

    It is not a very large project (especially when compared to GCC and LLVM) and it uses parts (for example, the preprocessor) of GCC.

    It optimizes the compiled source code with focusing on issues appearing on small devices.

    The intermediate code is not documented very well (there is a list of all the Icodes on the project's wiki) but is simple enough to be understandable.

    %does it?
%     Unlike the previous two compilers, it provides opcodes for operations such as port access %% TODO overit, nejsem si ted uplne jisty a nemam to u sebe

\chapter{Existing Solutions}\label{existing}

    \section{PCComp}\label{pccomp}

    Picoblaze C Compiler, the project of Francesco Poderico, has its own page on Sourceforge, \todo{link}
    yet there are no files to download or source code in the repository and the only relevant activity visible is a question where to actually download the compiler.

    I managed to find a Windows binary in version 1.8.4 in a web archive and a user manual describing the compiler's features, both created in year 2005 or 2006.

    However, the limitations of the compiler are vast. It generates stack-based code. This is unfortunate because PicoBlaze lacks any stack. 

        \subsection{Features}

        The compiler is not strictly following the C standard and implements only its small subset.

        PicoBlaze, PicoBlaze-2 and PicoBlaze-3 support.

        Byte and word (1 and 2 bytes) types only are supported.

        One-dimensional arrays without any pointer arithmetic are implemented by the compiler.

        \subsection{Limitations}

        Type conversions are missing, as are variable modifiers(e.g. \texttt{volatile}). 

        The compiler does not support any kind of resulting code optimization, except dead branch detection.

        To list some issues when the flaws of the previous PBCC\ref{prev_pbcc} are taken in question:

        The compiled assembly is often buggy or even nonfunctional and the probabilty of getting broken code is increasing with the complexity of the input source code and the arithmetic expressions in particular.

    \section{PBCC by Bohumil Nováček}\label{not_quite_c}

    %% https://dip.felk.cvut.cz/browse/details.php?f=F3&d=K13136&y=2008&a=xnovaceb&t=bach
    \todo{vic popsat, dodat link}
    This bachelor thesis was written on Faculty of Electrical Engineering of Czech Technical University in Prague in year 2008 when only PCComp\ref{pccomp} existed.

    Bohumil has written the program as a part of his bachelor thesis, resulting in great \todo{in great TODO}

        \subsection{Features}

        The compiler only allows the user to compile a small subset of the actual ISO/IEC 9899:1999 standard.

        Processor support is limited to PicoBlaze-3.

        The types supported are \texttt{void}, \texttt{char} and \texttt{int}.

        There is support for one-dimensional arrays only.

        \subsection{Limitations}

        There is no support for any user-defined type, be it only a typedef or a complex type (\texttt{struct}, \texttt{union}, \texttt{enum}).

    ,
    to name a few limitations, it is impossible to use nor \texttt{typedef} keywords, effectively limiting the user to use only the basic types which are in this case  (again 1 and 2 bytes).

    No expression conditions, strings and multidimensional arrays either are supported

    These limitations are caused by the fact Bohumil decided to write the compiler
    from scratch without usage of any framework or front-end and the fact the time needed to finish a complete C compiler is far beyond the time-frame of a bachelor thesis.

    However, despite its simplicity, some optimization is implemented, 
    such as constants and the results of constant expressions being replaced by values directly.

    Also, the source code is not to be found anywhere on the Internet, only the text part of the thesis was made public.


    \section{PBCC by Jakub Horník}\label{prev_pbcc}

    \todo{FIXME prepsat}

    PicoBlaze C Compiler is a project sponsored by Virtuální laboratoř aplikovaných mikroprocesorů \todo{Overit}
    realized on the Faculty of Information Technology, Brno University of Technology.

    It was written in years 2010 - 2011 by Jakub Horník as a part of his master's thesis and is now maintained by Zbyněk Křivka, supervisor of this thesis.

    The compiler is based on the Small Device C Compiler (SDCC) modified to provide support for the processor so it offers a subset of features of SDCC in version 3.0.

    There is support for adding further optimization methods provided by SDCC, additionally to its own optimizations those are ran during the compilation process on the intermediate code.

    Data types supported are integers large from 1 to 4 bytes, there is also no problem with converting them.

    Usage of arrays (even multidimensional) and pointers is implemented, including their usage as function parameters.

    PicoBlaze-6 was released only a few months after Jakub started writing the thesis for the previous one, PicoBlaze-3. 
    He did not focus on the new features at all and wrote the program only for the old one.
    This is the reason why function pointers left unimplemented and what I will be focusing on in this project.

    The main reason to rewrite the compiler from scratch is to avoid carrying all the legacy instructions and features and to focus on the cleanest possible implementation of the current revision of the processor.

    Jakub also suggests allocating the registers by coloring them and using the information for better results when memory access frequency is taken in question.

    This means I wrote the whole program again while using just a few parts from the original code.


\chapter{New Port Creation}\label{port}

SDCC is basically a framework for compiler creation, providing useful tools that make compiling for the programmer's platform easier.

The architecture of SDCC is based upon the so called \emph{ports}, units containing code related only to one target platform. These can be divided even further to provide more flexibility regarding different types of processors.

    \section{Adding a New Port}

    As this process is not documented anywhere in the SDCC documentation and doing it properly would require deep and good understanding of the GNU autotools toolchain, the following procedure was used to add the new port to the SDCC source:

    \begin{enumerate}

    \item Create a port source directory in \texttt{src/}, in this case, I was calling it \texttt{pblaze}.

    \item Add the basic source files in the port directory, for example \texttt{main.c} and \texttt{main.h}. \texttt{main.c} has to contain an instance of \texttt{PORT} structure containing information about the port's specifications and pointers to functions that will be called during the compilation.

    \item Insert a new (unique) port ID into \texttt{src/port.h}, like this for example:

    \texttt{\#define TARGET\_ID\_PBLAZE    16}

    \item And create an \texttt{extern} reference to the \texttt{PORT} instance from \texttt{src/pblaze/main.c}, for example:

\begin{verbatim}#if !OPT_DISABLE_PBLAZE
extern PORT pblaze_port;
#endif\end{verbatim}

    \item In \texttt{src/SDCCmain.c}, insert a reference to the structure defined in \texttt{src/pblaze/main.c}.

    \end{enumerate}

        \subsection{Automation of new port addition}

        These tasks are automated in the included \texttt{glue.sh} script. When it is executed in  Bash\footnote{Bourne Again Shell, http://www.gnu.org/software/bash/} with the \texttt{SDCC\_HOME} environment variable set to point to the directory with both PBCC and SDCC source code, it completes all the necessary tasks.

    \section{Compilation}

    After the port was added, SDCC can be compiled. The steps to achieve successful compilation are:

    \begin{enumerate}
    \item \texttt{autoconf} creates a \texttt{configure} script to configure the components and compiler options of the final binary
    \item \texttt{./configure} is a script that compiles a Makefile for the compilation itself. It is possible, for example, to modify the optimization of the compiler binary or disable compilation of \emph{ports} of architectures we will not need.
    \item \texttt{make} is the compilation script itself. You can speed the whole process by using the \texttt{-jX} argument specifying that \texttt{X} compiler processes should run at the same time.
    \end{enumerate}

    \section{Tools Used}

        \subsection{pBlazASM}\label{pblazasm}

        PBlazASM is an open source assembler created by Mediatronix to be used for compiling the machine code source files directly to machine code in several formats. It can also create a representation (\texttt{.lst} files) that is then used in the simulator \ref{pblazsim}.

        However, the program itself is bug infested and crashes quite often. There were some trivial bugs that were possible to be fixed quickly, such as calling \texttt{free()} on a pointer that was not returned by \texttt{malloc()}).

        \subsection{pBlazSIM}\label{pblazsim}

        As the debugging capabilities of the processor are limited and running the programs on real hardware would be too complicated, possibility of usage a simulator of the target processor is more than welcome.

        One of the most recent ones, pBlazSIM, was created by Mediatronix, too. It is written in C++ and Qt, so its usage is not limited only to the Windows platform which is the only one Mediatronix distributes the binary form to.

            \subsubsection{Running Under Linux}

            First attempts to run the simulator in \emph{Wine}\footnote{WINE is not an Emulator - an open source Windows API implementation} were quite unsuccessful as it was capable of simulation only the code which was included in the distributed binary package.

            \todo{Citace/linky}
            However, the application itself is hosted under the GPLv2 open source license in the Google Code repository. 

            It is impossible to compile it directly from the source provided (at least at the time of writing of the thesis). The needed steps to finish the compilation successfully are fixing the \texttt{qmake} project file to include all needed source files and adding one missing icon for the GUI (for example by copying the existing ones in different colors).

            The hand-compiled version is capable of running the assembly files generated by \ref{pblazasm} well, including all features of its graphical user interface.

            I contacted the upstream developer responsible for the changes that introduced the invalid constructions to fix them. By the time I'm writing this thesis, the code is already fine.

            \subsubsection{Command Line Simulator}

            Recently a simple simulator without any user interface was introduced to the code-base. The officially provided build system information does not handle its compilation but due to the relative simplicity of the project, it is easy to compile this executable by hand by using the object files of the pBlaze.cpp module.

            The simplest way possible (provided you use a C++ compiler that is able to link directly) to compile this binary is by using the following command:

            \begin{center}
                \texttt{\$\{CPP\} pBlaze.cpp pBlazSIMcl.cpp -o \$\{SIM\_BINARY\}}
            \end{center}

        \subsection{PBSim}\label{pbsim}

        \todo{Malo informaci, nakonec ho stejne nepouzivam... asi dat pryc uplne}

        A project that is being developed on the University, started as a Master's project in year 2012.

        Bound to \emph{SDCC}.

        Tightly related to Eclipse, it is possible to use it as a part of the user interface.

        \subsection{git}\label{git}

        Git is a Distributed Revision Control System allowing the user to create snapshots (\emph{commits}) of the source code and store them in remote repositories.

        It focuses on speed and team development. 

        The whole project is hosted under the GPLv2 license on Github\footnote{https://github.com/krivka/pbccv3}.

        


\chapter{Implementation Design}\label{design}

In this chapter, the technical details of the project are discussed.

    \todo{Pravdepodobne vetsina veci moc do hloubky, prehodnotit prepsani na mene implementacni, vice abstrakce}

    \section{Base Layer}

    Using pure C library calls and macros in a C++ project would be wasting potential of the language, that's why the project is building upon a wrapper library for the \emph{SDCC} internals instead of them directly.

    The whole wrapper library is included in the \texttt{wrap.h} and \texttt{wrap.cc} files.

        \subsection{Approach}

        Every needed \emph{SDCC} structure is wrapped in its own class adding new methods.

        The C++ classes are inheriting the structures themselves (to provide ability to up-cast directly).

        No other member variables are added, the memory footprint is the same. Actually, the pointers between the classes and their parent structures can be converted safely in both ways. This is not encouraged though as there is no support for this operation implicitly in the language standard.

        \subsection{Solution}

        Most of the code is generated using regular expressions, then modified by hand to provide the required functionality.

        The methods added to the classes are usually just wrapping the functions and macros from \emph{SDCC}.

        There were some, unfortunately, that required being copied over to the code due to higher type safety of C++ when compared to C. This is the case of \texttt{bool ICode::skipNoOp()} method for example.

    \section{Utility Classes}

    To provide better readable code and easier debugging, there are some classes provided.

    Everything covered here can be found in the \texttt{util.h} and \texttt{util.cc} files.

        \subsection{Emitter}\label{emitter}

        Working in a similar fashion to the streams in the \emph{C++ STL} library, this class implements the final assembly output.

        The single global instance of this class is initialized on start-up, configuring the output file and output format to hide these details from the generating code itself.

        Streaming (or left shift) operators are overloaded to make the instruction emitting stand out from the code.

        Many instructions have different forms for single- and multi- byte variables used as their operands. For this purpose, the class also provides an iterator variable, declared as \texttt{static public int i}.

    \section{Instruction Generator}

    \texttt{gen.h} and \texttt{gen.cc}

    To avoid code duplication as much as possible, every instruction is generated using cycles wrapping the \texttt{Emitter}\ref{emitter} class.

    This helps code clarity in the \texttt{ICode} processing functions themselves, limiting it to pure logic of handling the needed information.

    \section{Variable Storage}

    All the included sections are named after the classes in the source code to provide a comprehensible description of their purpose.

    \texttt{ralloc.h} and \texttt{ralloc.cc}

        \subsection{Allocator}

        Singleton class used as an entrance to the generator itself.

        \subsection{Byte Subclasses - MemoryCell and Register}

        \subsection{Bank}

        Two instances of this class are present in the compiler, corresponds to each register bank contained in the processor.

        It collects all 16 registers and manages their allocation for variables and handles their clearing or moving to memory.

        \subsection{Memory}

    \section{Compiled Assembly Properties}

    The compiler is producing commented assembly to be given to an assembler which then in turn produces various its binary equivalents or other formats, for example suitable for simulation.

    In this section, the vital properties, required for getting grasp of the code (for its further modification by hand, for example), are discussed.

        \subsection{Calling Conventions}

        The calling conventions were designed to utilize as much of the variables as possible because of the limited capabilities of the processor.

        Registers are saved to the function's stack by the caller, considering liveness of the variables.

        The arguments are stored consecutively in little-endian order \footnote{The least significant byte is stored first, the most significant one last} in the registers.

        For example, consider the following function:

        \begin{center}
            \texttt{int mul4b(int l, int r);}
        \end{center}

        Its initial register utilization would be as follows:

        \begin{center}\begin{tabular}{ | c | c | c | c | c | c | c | c | }
            \hline
            \texttt{s0} & \texttt{s1} & \texttt{s2} & \texttt{s3} & \texttt{s4} & \texttt{s5} & \texttt{s6} & \texttt{s7} \\
            \hline
            \texttt{l[0]} & \texttt{l[1]} & \texttt{l[2]} & \texttt{l[3]} & \texttt{r[0]} & \texttt{r[1]} & \texttt{r[2]} & \texttt{r[3]} \\
            \hline
            \hline
            \texttt{s8} & \texttt{s9} & \texttt{sA} & \texttt{sB} & \texttt{sC} & \texttt{sD} & \texttt{sE} & \texttt{sF} \\
            \hline
            free & free & free & free & free & free & free & \texttt{SP}\footnote{Stack Pointer} \\
            \hline
        \end{tabular}\end{center}

        The returned value is stored in the first registers in the same way as the parameters were stored. Little-endian order limits the register usage in the caller to the bare minimum.

        Restoring of the saved registers is done in the caller, too.

        \subsection{Function Pointers}

        As mentioned in new feature overview\ref{jumpat}, the processor now supports jumping to labels and calling functions that have their address loaded on run-time.

        To make use of as much of the new specification as possible, the compiler supports calling function pointers using the \texttt{CALL@} instruction.

        Prior to the instruction invocation itself, the function pointer is stored in the \texttt{sD} and \texttt{sE} registers. As the address of a function is larger than the size of one register, it has to be stored in two of them - \texttt{sD} cointains the upper 4 bits of the address and \texttt{sE} the lower 8 bits.

        Rather than limiting all functions' arguments to reserve the two registers for a possible function pointer call, only pointers to functions with lesser than 13 bytes worth of arguments is possible.

        Other than this, there is no limitation to function pointer usage.

        \subsection{Register Bank Utilization}

        From the perspective of register banks, there are two types of functions (as there are two banks). 

        The first type is either function \texttt{main} or a state when the program has not entered \texttt{main} yet. This code has access only to variables stored in registers in \texttt{Bank A}.

        The other type are all other functions. These have access to registers in Bank B.

        Bank selection is handled from the code of the first type. This makes the other functions able to call any other function including itself. Any kind of recursion including \texttt{main} is not supported though.

        Before and after the call, bank has to be switched to the appropriate one. Also, if the function returned any value, it has to be transferred from the other bank to the current one before the bank is switched.

        In effect, this makes having most of the program logic in the \texttt{main} function, as it does not have to store most of its registers before calling a function, thus reducing the number of necessary \texttt{FETCH} and \texttt{STORE} instructions to move the local variables in the stack memory.

        \subsection{Stack and Variable Storage}

        Local variables of the program are initially created in the registers. Only once there is not enough room for any other variable needed for an operation in future, it is freed from the register and stored on the stack.

        Stack pointer is stored only in register \texttt{sF} only in \texttt{Bank B}. Stack pointer is not tracked in the \texttt{main} function. As does register bank selection, this also makes recursive calls to \texttt{main} impossible.

        The \texttt{sF} register in \texttt{main} is used only as a temporary storage for loading literal values into registers in the other register bank and to access the local variables' addresses.

        \subsection{Arithmetic Operations}

        Only basic arithmetic supported by the processor is implemented, that means there is no basic support for multiplication nor division of the variables.

        The functions to mutliply can be extracted from the previous PBCC\ref{prev_pbcc} and inserted as inline assembly in a separate function, according to the calling functions.

        Other than that, the operations are utilizing the improved instructions handling multi-byte variables in minimum cycles.

        \subsection{Comments in the Code}

        To improve the readability and comprehensiveness of the code, there are explanatory comments included in the compiled assembly.

            \subsubsection{Instruction Comments}

            Lines of most of the instructions contain a short comment explaining the instruction and its operands. This covers moves and arithmetic operations especially.

            To demonstrate, when the following code snippet is compiled:

            \begin{center}\texttt{int baz = 42 + foo - bar;}\end{center}

            Then, assuming the variable was not loaded in the registers beforehand and the other variables were already used (\texttt{foo} is in \texttt{s0} and \texttt{s1} and \texttt{bar} is in \texttt{s2} and \texttt{s3}), the resulting assembly will take the following form:

            \begin{center}
\begin{verbatim}load    s4,     s0              ; iTemp0[0]=foo[0]
load    s5,     s1              ; iTemp0[1]=foo[0]
add     s4,     0x2a            ; iTemp0[0]+=(value)
                                ; iTemp1=iTemp0
sub     s4,     s2              ; iTemp1[0]-=bar[0]
subcy   s5,     s3              ; iTemp1[1]-=bar[1]
                                ; baz=iTemp1\end{verbatim}\end{center}

            Each byte in the operation is covered with the regular C-style array notation.

            Also, notice only one byte of the literal value \texttt{42} (that is lower than the size of one byte) is being added to \texttt{iTemp0}. 

            Moves on temporary variables to next variables in a more complex expressions are optimized out, too. They are marked in the assembly to point out that an other variable now resides in the particular registers.

            \subsubsection{Function Comments}

            Every function is prepended with a comment that states its name with a list of its arguments. Every argument's name is written in the list along with the registers it is stored in, in case it is not stored on stack directly.

            For example, consider the following function:

            \begin{center}\texttt{char func(long arg1, int arg2, char arg3);}\end{center}

            Its representation in the assembly will be prepended with this comment:

            \begin{center}\texttt{; Function func, arguments: [arg1:\{s0,s1,s2,s3,\},arg2:\{s4,s5,\},arg3:\{s6,\},]}\end{center}

            

    \section{Testing}

    Several example source files were compiled and ran in a simulator to prove the resulting assembly corresponds to the input source code.

        \subsection{Tools and the Testing Process}

        \texttt{PBlazSIM}\ref{pblazsim} was chosen to simulate the resulting code due to its simplicity, maturity and liveliness of the upstream developers. 

            \subsubsection{Obtaining the Simulation Result}

                The simplicity of \texttt{PBlazSIM} cleared the way for modifying of the (small) codebase and including it as a part of the test-suite in this project.

                The only modification done is as follows: When the simulation ends because of an error or reaches the correct final state of the simulation (this happens once it  the \texttt{BREAK} internal opcode is processed), it prints the state of the processor to the standard output.

                The output is formatted for easy parsing and usage in the attached test suite.

            \subsubsection{Assembler}

                The input to \texttt{PBlazSIM} are rich assembly language files enhanced with binary representation of the code it is about to simulate. This format is compiled using \texttt{PBlazASM}\ref{pblazasm} using the \texttt{\-l} flag and results in a \texttt{.LST} extended file.

                There were no special modifications required to get the needed results except the ones mentioned in \ref{pblazasm}.

        \subsection{The Framework}

        All scripts are ran recursively for each \texttt{.c} and \texttt{.tst} file in the \texttt{test} directory in the root of the code tree.

        Every \texttt{.c} file has to have its counter-part with the same base name (except the suffix) to be considered a valid test.

        It tests the memory and the registers for presence of any value given (with the exception of omitted zero values, considering major part of the memory will be free in most cases), be it on a specifically given position or anywhere.

        It is also possible to test \texttt{ZERO} and \texttt{CARRY} flags of the processor.

            \subsubsection{Test File Format}

            The \texttt{.tst} file format requires every such file to include declaration of every of the following variables:

            \begin{center}
            \begin{tabular}{ r | l }
                \texttt{stored\_somewhere} & \todo{...}\\

                \texttt{stored\_there} & \todo{...}\\

            \end{tabular}
            \end{center}

            The variables are declared and defined in pseudo-C style (without the type specification), that means: enumerations take a brace-enclosed list as their initializer and boolean values can be either \texttt{true} or \texttt{false}.

            Every definition has to be ended with a semicolon. Double definitions will result in a failing test.

            For example, the following declaration will check all memory locations to contain the values 1, 2 and 3:

            \begin{center}
                \texttt{stored\_somewhere = \{1, 002, 0x3\};}
            \end{center}

            Note that the first value is in decimal system, the second one is octal and the last one hexadecimal.

        \subsection{Test Cases}

            \todo{Hodi se poznamenat, ze testy presne v te podobe, kterou popisuju neexistuji, jsou tak nejak random}
            \begin{center}
            \begin{tabular}{ r | l }
                \texttt{null.c} & Doesn not compute anything, tests if the whole stack works \\
                \texttt{basic.c} & Basic variable assignment \\
                \texttt{addsub.c} & Addition and subtraction \\
                \texttt{bitlogic.c} & Binary operation on the variables \\
                \texttt{muldiv.c} & Multiplication and division \\
                \texttt{condsimple.c} & Simple condition evaluation \\
                \texttt{condcomplex.c} & Complicated condition evaluation \\
                \texttt{function.c} & Function calling \\
            \end{tabular}
            \end{center}

\chapter{Port Features}\label{features}

    \section{Code Clarity}

    \todo{extensibility asi neni slovo}
    The extensibility and readability of this port is not comparable to any other port. The code generation itself takes only about 5 lines of code for each \texttt{ICode}, compared to tens to hundreds in PBCCv2\ref{prev_pbcc}.

    Providing a C++ API also helps by providing more syntax sugar for anybody who wants to further modify the compiler. Using class methods instead of macros and functions also adds the possibility to use an IDE\footnote{Integrated Development Environment} with method suggestion.

    \section{KCPSM6 Support}

    There is no other compiler designed to produce code for the newest revision of the PicoBlaze processor.

    The most modern ones support only KCPSM3 so they miss the opportunity to save not only the program space (meaning less CPU cycles for the same program) but also the scratchpad memory and registers (which means the program will utilize less CPU cycles again).

\chapter{Conclusion}\label{conclusion}


\cite{TBD}
%=========================================================================
